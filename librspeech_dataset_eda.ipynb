{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19aRtqWStMYtYt5GOEzfsynT364KArD_r",
      "authorship_tag": "ABX9TyOqhWawH+/h1fwC46yzGX3n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wasimmadha/dubbing-project-research/blob/main/librspeech_dataset_eda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBs_EAB-B3Oe"
      },
      "outputs": [],
      "source": [
        "!tar -xzf '/content/drive/MyDrive/Dubbing Project/libspeech/dev-clean.tar.gz' -C /content/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzf '/content/drive/MyDrive/Dubbing Project/libspeech/train-clean-100.tar.gz' -C /content/"
      ],
      "metadata": {
        "id": "9kTwYOqqE26p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pronouncing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC5VIaaEarfU",
        "outputId": "5f6648d5-75b9-4326-d9db-7808ba4ab9c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pronouncing\n",
            "  Downloading pronouncing-0.2.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cmudict>=0.4.0 (from pronouncing)\n",
            "  Downloading cmudict-1.0.18-py3-none-any.whl (939 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.4/939.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.10/dist-packages (from cmudict>=0.4.0->pronouncing) (7.0.1)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.10/dist-packages (from cmudict>=0.4.0->pronouncing) (6.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=5->cmudict>=0.4.0->pronouncing) (3.17.0)\n",
            "Building wheels for collected packages: pronouncing\n",
            "  Building wheel for pronouncing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pronouncing: filename=pronouncing-0.2.0-py2.py3-none-any.whl size=6234 sha256=596b9ee0187ae997a4668cf9071b3f9ab6e45891797b0062ef68ed2030dc8a85\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/f6/1d/599c67da1fa48c086d8c49e8fc6bd5f05bc9fa66fb04bed5db\n",
            "Successfully built pronouncing\n",
            "Installing collected packages: cmudict, pronouncing\n",
            "Successfully installed cmudict-1.0.18 pronouncing-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "\n",
        "import torchaudio\n",
        "import pronouncing\n"
      ],
      "metadata": {
        "id": "sVLXTHotPtyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_filename_and_text(input_string):\n",
        "    parts = input_string.split(None, 1)\n",
        "\n",
        "    if len(parts) == 2:\n",
        "        filename, text = parts\n",
        "        return filename, text\n",
        "    else:\n",
        "        print(\"Error: Unable to split filename and text.\")\n",
        "        return None, None\n"
      ],
      "metadata": {
        "id": "s35MIybnOaa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_text_to_phonemes(text):\n",
        "    result = []\n",
        "    for word in text.split():\n",
        "        # Get phonemes for the word\n",
        "        phones = pronouncing.phones_for_word(word)\n",
        "\n",
        "        if len(phones) > 1:\n",
        "            phones = [phones[1]]\n",
        "        # Append the phonemes to the result\n",
        "        result.extend(phones)\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "xouWQPJPamo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"foreign french\"\n",
        "convert_text_to_phonemes(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvMs_IuJjSWy",
        "outputId": "12807597-947f-4f3d-ec8e-cd76860e8718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['F AA1 R AH0 N', 'F R EH1 N CH']"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mapped_librspeech_data(main_folder_path):\n",
        "    output_dict = {}\n",
        "\n",
        "    for main_speaker_dir in os.listdir(main_folder_path):\n",
        "        main_speaker_path = os.path.join(main_folder_path, main_speaker_dir)\n",
        "        for sub_speaker_dir in os.listdir(main_speaker_path):\n",
        "            sub_speaker_path = os.path.join(main_speaker_path, sub_speaker_dir)\n",
        "            files_list = os.listdir(sub_speaker_path)\n",
        "            txt_file = [file for file in files_list if file.endswith(\".txt\")][0]\n",
        "            txt_file = os.path.join(sub_speaker_path, txt_file)\n",
        "            with open(txt_file, 'r', encoding='utf-8') as file:\n",
        "                lines = file.readlines()\n",
        "\n",
        "            for line in lines:\n",
        "              filename, text = split_filename_and_text(line)\n",
        "\n",
        "              file_path = os.path.join(sub_speaker_path, filename+'.flac')\n",
        "\n",
        "              waveform, sample_rate = torchaudio.load(file_path)\n",
        "\n",
        "              phonemes_result = convert_text_to_phonemes(text)\n",
        "              phonemes = ' '.join(phonemes_result)\n",
        "\n",
        "              if '# foreign french' in phonemes:\n",
        "                  phonemes = phonemes.replace('# foreign french', '')\n",
        "\n",
        "              if 'foreign' in phonemes or 'french' in phonemes:\n",
        "                print(text)\n",
        "                print(phonemes_result)\n",
        "\n",
        "              output_dict[filename] = {\n",
        "                  \"file_path\": file_path,\n",
        "                  \"text\": text,\n",
        "                  \"phonemes\": phonemes.split()\n",
        "              }\n",
        "\n",
        "\n",
        "    return output_dict\n",
        "\n",
        "\n",
        "\n",
        "        # for files in os.listdir(sub_speaker_path):\n",
        "        #   print(files)"
      ],
      "metadata": {
        "id": "wohzP6mPFs7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_folder_path = '/content/LibriSpeech/train-clean-100'\n",
        "valid_folder_path = '/content/LibriSpeech/dev-clean'\n",
        "\n",
        "train_output_dict = get_mapped_librspeech_data(train_folder_path)\n",
        "valid_output_dict = get_mapped_librspeech_data(valid_folder_path)"
      ],
      "metadata": {
        "id": "knNfDBBfRKk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train_output_dict.json', 'w') as file:\n",
        "    json.dump(train_output_dict, file)\n",
        "\n",
        "with open('valid_output_dict.json', 'w') as file:\n",
        "    json.dump(valid_output_dict, file)"
      ],
      "metadata": {
        "id": "mxXgcQiyE8Me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(train_output_dict.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRDjMocOdhEm",
        "outputId": "505c203a-dde7-47cc-c5d2-35c8be0e927e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28539"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_total_phonemes = []\n",
        "for key in list(train_output_dict.keys()):\n",
        "    phonemes = train_output_dict[key][\"phonemes\"]\n",
        "    if 'foreign' in phonemes:\n",
        "      print(key, train_output_dict[key])\n",
        "    train_total_phonemes.extend(phonemes)\n",
        "\n",
        "train_total_phonemes = set(train_total_phonemes)\n",
        "print(\"total train phonemes: \", len(train_total_phonemes), train_total_phonemes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M77KY8dRDrV",
        "outputId": "b73a925d-c00a-444c-abf1-7855d1926ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total train phonemes:  72 {'AA2', 'EY1', 'CH', 'ZH', 'L', 'DH', 'AA1', 'W', 'SH', 'AY1', 'IY0', 'UW0', 'OY0', 'UH2', 'ER0', 'D', 'Y', 'UH1', 'EY2', 'K', 'S', 'AH2', 'OY2', 'HH', 'AO2', 'IY1', 'AY2', 'OW0', 'IH0', 'T', 'IH1', 'AW2', 'EH0', 'org,', 'AO1', 'EH1', 'EH2', 'R', 'NG', '#', 'UW2', 'IH2', 'EY0', 'UH0', 'JH', 'ER2', 'V', 'IY2', 'G', 'M', 'AH1', 'AE2', 'OY1', 'AE1', 'AW0', 'OW2', 'N', 'B', 'irish', 'AE0', 'AA0', 'AY0', 'OW1', 'F', 'P', 'TH', 'AH0', 'UW1', 'AW1', 'ER1', 'AO0', 'Z'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_total_phonemes = []\n",
        "for key in list(valid_output_dict.keys()):\n",
        "    phonemes = valid_output_dict[key][\"phonemes\"]\n",
        "    valid_total_phonemes.extend(phonemes)\n",
        "\n",
        "valid_total_phonemes = set(valid_total_phonemes)\n",
        "print(\"total train phonemes: \", len(valid_total_phonemes), valid_total_phonemes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EODNTpJc0cZ",
        "outputId": "a21e9c95-a14e-4c5f-d4c6-de12432f1104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total train phonemes:  71 {'AA2', 'EY1', 'CH', 'ZH', 'L', 'DH', 'IY0', 'AY1', 'SH', 'W', 'AA1', 'UW0', 'UH2', 'ER0', 'Y', 'D', 'UH1', 'EY2', 'K', 'S', 'AH2', 'OY2', 'HH', 'AO2', 'IY1', 'AY2', 'OW0', 'IH0', 'T', 'IH1', 'AW2', 'EH0', 'org,', 'AO1', 'EH1', 'R', 'NG', 'EH2', '#', 'UW2', 'IH2', 'EY0', 'UH0', 'JH', 'ER2', 'V', 'IY2', 'G', 'M', 'AH1', 'AE2', 'OY1', 'AE1', 'AW0', 'OW2', 'B', 'N', 'irish', 'AE0', 'AA0', 'AY0', 'OW1', 'F', 'P', 'UW1', 'AH0', 'AW1', 'ER1', 'TH', 'AO0', 'Z'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'foreign' in train_total_phonemes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUqgDVcpjFTn",
        "outputId": "4f287f06-b0e4-47b3-9fb3-2df84cf23ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_total_phonemes"
      ],
      "metadata": {
        "id": "uGmET7dri9z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_phonemes = list(train_total_phonemes.union(valid_total_phonemes))\n",
        "len(list(total_phonemes)), list(total_phonemes)"
      ],
      "metadata": {
        "id": "Ot0v_dzxdcIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_phoneme_dict = {index: phoneme for index, phoneme in enumerate(total_phonemes)}\n",
        "phoneme_dict = {phoneme: index for index, phoneme in enumerate(total_phonemes)}\n"
      ],
      "metadata": {
        "id": "USvEJ6EleFCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_phoneme_dict\n",
        "phoneme_dict"
      ],
      "metadata": {
        "id": "FI_bLERCES3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('phoneme_dict.json', 'w') as file:\n",
        "    json.dump(phoneme_dict, file)\n",
        "\n",
        "with open('reverse_phoneme_dict.json', 'w') as file:\n",
        "    json.dump(reverse_phoneme_dict, file)\n"
      ],
      "metadata": {
        "id": "mBkr8rtfEZBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('phoneme_dict.json', 'r') as file:\n",
        "    loaded_phoneme_dict = json.load(file)\n"
      ],
      "metadata": {
        "id": "ztySMEhFEvJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_phoneme_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjeBDPlaE1P-",
        "outputId": "139ed111-19b6-4d74-b55f-023e1297be68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AA2': 0,\n",
              " 'CH': 1,\n",
              " 'ZH': 2,\n",
              " 'DH': 3,\n",
              " 'UW0': 4,\n",
              " 'W': 5,\n",
              " 'IY0': 6,\n",
              " 'OY0': 7,\n",
              " 'UH2': 8,\n",
              " 'D': 9,\n",
              " 'Y': 10,\n",
              " 'Z': 11,\n",
              " 'OY2': 12,\n",
              " 'HH': 13,\n",
              " 'AY2': 14,\n",
              " 'IH0': 15,\n",
              " 'EH1': 16,\n",
              " 'UW2': 17,\n",
              " 'UH0': 18,\n",
              " 'JH': 19,\n",
              " 'ER2': 20,\n",
              " 'V': 21,\n",
              " 'IY2': 22,\n",
              " 'G': 23,\n",
              " 'M': 24,\n",
              " 'AH1': 25,\n",
              " 'irish': 26,\n",
              " 'AA0': 27,\n",
              " 'AY0': 28,\n",
              " 'OW1': 29,\n",
              " 'ER1': 30,\n",
              " 'AO0': 31,\n",
              " 'EY1': 32,\n",
              " 'L': 33,\n",
              " 'AA1': 34,\n",
              " 'AY1': 35,\n",
              " 'SH': 36,\n",
              " 'ER0': 37,\n",
              " 'AH0': 38,\n",
              " 'UH1': 39,\n",
              " 'K': 40,\n",
              " 'S': 41,\n",
              " 'AH2': 42,\n",
              " 'AO2': 43,\n",
              " 'IY1': 44,\n",
              " 'OW0': 45,\n",
              " 'T': 46,\n",
              " 'IH1': 47,\n",
              " 'AW2': 48,\n",
              " 'EH0': 49,\n",
              " 'org,': 50,\n",
              " 'AO1': 51,\n",
              " 'NG': 52,\n",
              " 'EH2': 53,\n",
              " 'R': 54,\n",
              " '#': 55,\n",
              " 'EY0': 56,\n",
              " 'AW0': 57,\n",
              " 'AE2': 58,\n",
              " 'AE1': 59,\n",
              " 'OW2': 60,\n",
              " 'N': 61,\n",
              " 'B': 62,\n",
              " 'AE0': 63,\n",
              " 'F': 64,\n",
              " 'AW1': 65,\n",
              " 'P': 66,\n",
              " 'TH': 67,\n",
              " 'EY2': 68,\n",
              " 'IH2': 69,\n",
              " 'UW1': 70,\n",
              " 'OY1': 71}"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D5xp8PzvE2HE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}